{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/06 09:13:37 WARN Utils: Your hostname, codespaces-8bb66a resolves to a loopback address: 127.0.0.1; using 10.0.0.133 instead (on interface eth0)\n",
      "24/12/06 09:13:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/06 09:13:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "[Stage 0:====================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'DEN': 46, 'CAN': 37, 'IAH': 37, 'ATL': 36, 'ORD': 33, 'KUL': 33, 'CGK': 27, 'JFK': 25, 'LHR': 25, 'CDG': 21, 'CLT': 21, 'PVG': 20, 'LAS': 17, 'BKK': 17, 'AMS': 15, 'FCO': 15, 'MUC': 14, 'MAD': 13, 'PEK': 13, 'HND': 13, 'DFW': 11, 'MIA': 11})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from functools import reduce\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "def load_dataset(filename, columnNames):\n",
    "    df = pd.read_csv(filename,encoding='latin1',names=columnNames) #need to define encoding or it all breaks. As any other type of encoding breaks everything after\n",
    "    return df\n",
    "\n",
    "def get_instances(data): #get each individual item\n",
    "    instances = data.split()\n",
    "    return Counter(instances)\n",
    "\n",
    "def ReduceCounter(counter1, counter2): #count how many times a value appears\n",
    "    counter1.update(counter2)\n",
    "    return counter1\n",
    "\n",
    "conf = SparkConf().setAppName('MapReduce').setMaster('local')\n",
    "sparkContext = SparkContext.getOrCreate(conf=conf)\n",
    "spark = SparkSession.builder.appName(\"AllowConversion\").getOrCreate() #this is used to convert from a panda dataframe to a pyspark dataframe\n",
    "\n",
    "columns = ['passengerID', 'flightID', 'originAirport', 'destinationAirport', 'departureTime', 'flightTime']\n",
    "\n",
    "rdd = load_dataset(\"AComp_Passenger_data_no_error.csv\", columns)\n",
    "\n",
    "Origins = rdd['originAirport'].tolist()\n",
    "distributed_data_origins = sparkContext.parallelize(Origins, 10)\n",
    "\n",
    "dist_data_flight_origins = distributed_data_origins.map(get_instances)\n",
    "dist_data_flight_origins_count = dist_data_flight_origins.reduce(ReduceCounter)\n",
    "print(dist_data_flight_origins_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:====================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    flightID originAirport departureTime destinationAirport  flightTime  \\\n",
      "0   SQU6245R           DEN         10:14                FRA        1049   \n",
      "1   XXQ4064B           JFK         12:05                FRA         802   \n",
      "2   SOH3431A           ORD         11:00                MIA         250   \n",
      "3   PME8178S           DEN         10:13                PEK        1322   \n",
      "4   MBA8071P           KUL         01:04                PEK         572   \n",
      "5   MOO1786A           MAD         17:56                FRA         184   \n",
      "6   HUR0974O           DEN         10:15                PVG        1398   \n",
      "7   GMO5938W           LHR         17:11                PEK        1057   \n",
      "8   DAU2617A           CGK         00:23                SFO        1811   \n",
      "9   RUM0422W           MUC         17:58                MAD         194   \n",
      "10  ATT7791R           AMS         18:13                DEN        1001   \n",
      "11  WPW9201U           DFW         11:21                PEK        1452   \n",
      "12  DKZ3042O           MIA         12:05                SFO         538   \n",
      "13  QHU1140O           CDG         18:14                LAS        1133   \n",
      "14  ULZ8130D           CAN         01:23                DFW        1683   \n",
      "15  VYU9214I           ORD         11:18                DXB        1510   \n",
      "16  HZT2506M           IAH         11:12                AMS        1044   \n",
      "17  EWH6301Y           CAN         01:22                DFW        1683   \n",
      "18  VYW5940P           LAS         09:26                SIN        1843   \n",
      "19  WSK1289Z           CLT         11:59                DEN         278   \n",
      "20  TMV7633W           CGK         00:05                DXB         849   \n",
      "21  FYL5866L           ATL         12:25                HKG        1751   \n",
      "22  BER7172M           KUL         01:26                LAS        1848   \n",
      "23  JVY9791G           PVG         01:16                FCO        1189   \n",
      "24  VDC9164W           FCO         18:18                LAS        1276   \n",
      "25  KJR6646J           IAH         11:26                BKK        1928   \n",
      "26  YZO4444S           BKK         00:28                MIA        2027   \n",
      "27  XIL3623J           PEK         01:13                LAX        1302   \n",
      "28  RPG3351U           HND         01:59                CAN         374   \n",
      "29  XOY7948U           ATL         12:07                LHR         877   \n",
      "\n",
      "    passengerCount arrivalTime  \n",
      "0               21       11:43  \n",
      "1               25       07:27  \n",
      "2               18       16:10  \n",
      "3               18       23:15  \n",
      "4               16       10:36  \n",
      "5               13       21:00  \n",
      "6                7       00:33  \n",
      "7               25       18:48  \n",
      "8               12       15:34  \n",
      "9               14       21:12  \n",
      "10              15       02:54  \n",
      "11              11       01:33  \n",
      "12              11       18:03  \n",
      "13              21       04:07  \n",
      "14              27       15:26  \n",
      "15              15       22:28  \n",
      "16              14       11:36  \n",
      "17              10       15:25  \n",
      "18              17       08:09  \n",
      "19              21       14:37  \n",
      "20              15       11:14  \n",
      "21              20       06:36  \n",
      "22              17       16:14  \n",
      "23              20       14:05  \n",
      "24              15       06:34  \n",
      "25              23       08:34  \n",
      "26              17       22:15  \n",
      "27              13       06:55  \n",
      "28              13       07:13  \n",
      "29              16       07:44  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Flight ID, Count of Passengers, Departure code, Departure Time, Arrival Code, Arrival Time\n",
    "from pytz import timezone\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def GetFlightInfo(acc, record):\n",
    "    flightID = record['flightID']\n",
    "\n",
    "    if flightID not in acc:\n",
    "        acc[flightID] = record\n",
    "    return acc\n",
    "\n",
    "airportTimezones = {\n",
    "    \"ATL\": \"America/New_York\",\n",
    "    \"PEK\": \"Asia/Shanghai\",\n",
    "    \"LHR\": \"Europe/London\",\n",
    "    \"ORD\": \"America/Chicago\",\n",
    "    \"HND\": \"Asia/Tokyo\",\n",
    "    \"LAX\": \"America/Los_Angeles\",\n",
    "    \"CDG\": \"Europe/Paris\",\n",
    "    \"DFW\": \"America/Chicago\",\n",
    "    \"FRA\": \"Europe/Berlin\",\n",
    "    \"HKG\": \"Asia/Hong_Kong\",\n",
    "    \"DEN\": \"America/Denver\",\n",
    "    \"DXB\": \"Asia/Dubai\",\n",
    "    \"CGK\": \"Asia/Jakarta\",\n",
    "    \"AMS\": \"Europe/Amsterdam\",\n",
    "    \"MAD\": \"Europe/Madrid\",\n",
    "    \"BKK\": \"Asia/Bangkok\",\n",
    "    \"JFK\": \"America/New_York\",\n",
    "    \"SIN\": \"Asia/Singapore\",\n",
    "    \"CAN\": \"Asia/Shanghai\",\n",
    "    \"LAS\": \"America/Los_Angeles\",\n",
    "    \"PVG\": \"Asia/Shanghai\",\n",
    "    \"SFO\": \"America/Los_Angeles\",\n",
    "    \"PHX\": \"America/Phoenix\",\n",
    "    \"IAH\": \"America/Chicago\",\n",
    "    \"CLT\": \"America/New_York\",\n",
    "    \"MIA\": \"America/New_York\",\n",
    "    \"MUC\": \"Europe/Berlin\",\n",
    "    \"KUL\": \"Asia/Kuala_Lumpur\",\n",
    "    \"FCO\": \"Europe/Rome\",\n",
    "    \"IST\": \"Europe/Istanbul\"\n",
    "}\n",
    "\n",
    "def CalculateTimes(acc, record):\n",
    "    flightID, originAirport, departureTime, destinationAirport, flightTime = record #get parts of the record that are needed\n",
    "\n",
    "    depRealTime = datetime.fromtimestamp(departureTime, timezone(airportTimezones[originAirport])) #apply timezone to origin\n",
    "    flightDelta = timedelta(minutes=flightTime) #work out the minutes from the flight time\n",
    "\n",
    "    arrivalTime = depRealTime + flightDelta #calculate arrival time\n",
    "    arrivalTime = arrivalTime.astimezone(timezone(airportTimezones[destinationAirport])) #apply destination timezone\n",
    "    arrivalTimeFormat = arrivalTime.strftime('%H:%M') #format time\n",
    "    depTimeFormat = depRealTime.strftime('%H:%M')\n",
    "\n",
    "    acc.append({\n",
    "        \"flightID\": flightID,\n",
    "        \"departureTime\": depTimeFormat,\n",
    "        \"arrivalTime\": arrivalTimeFormat\n",
    "    })\n",
    "\n",
    "    return acc\n",
    "\n",
    "Flights = rdd['flightID'].tolist()\n",
    "distributed_data_flights = sparkContext.parallelize(Flights, 10)\n",
    "\n",
    "dist_data_flight_id = distributed_data_flights.map(get_instances)\n",
    "dist_data_flight_id_count = dist_data_flight_id.reduce(ReduceCounter)\n",
    "\n",
    "dist_data_flight_id_list = list(dist_data_flight_id_count.keys())\n",
    "\n",
    "#Getting data about each flight\n",
    "FirstFlightInfo = reduce(GetFlightInfo, [record for _, record in rdd.iterrows()], {})\n",
    "flightIDs = [record['flightID'] for record in FirstFlightInfo.values()]\n",
    "originAirports = [record['originAirport'] for record in FirstFlightInfo.values()]\n",
    "departureTimes = [record['departureTime'] for record in FirstFlightInfo.values()]\n",
    "destinationAirports = [record['destinationAirport'] for record in FirstFlightInfo.values()]\n",
    "flightTimes = [record['flightTime'] for record in FirstFlightInfo.values()]\n",
    "FlightInfo = pd.DataFrame({\n",
    "    'flightID': flightIDs,\n",
    "    'originAirport': originAirports,\n",
    "    'departureTime': departureTimes,\n",
    "    'destinationAirport': destinationAirports,\n",
    "    'flightTime': flightTimes\n",
    "})\n",
    "\n",
    "#get the flightID and number of Passengers \n",
    "FlightData = pd.DataFrame({\n",
    "    'flightID': list(dist_data_flight_id_count.keys()),\n",
    "    'passengerCount': list(dist_data_flight_id_count.values())\n",
    "})\n",
    "\n",
    "df = pd.merge(FlightInfo, FlightData, on='flightID', how='inner')\n",
    "\n",
    "FlightInfoTuples = FlightInfo[['flightID', 'originAirport', 'departureTime', 'destinationAirport', 'flightTime']].itertuples(index=False) #Convert to tuples so can use reduce\n",
    "\n",
    "CalcTime = reduce(CalculateTimes, FlightInfoTuples, []) #use a reduce with tuples input and the function CalculateTimes\n",
    "CalcTimeFI = [flight['flightID'] for flight in CalcTime]\n",
    "CalcTimeDT = [flight['departureTime'] for flight in CalcTime]\n",
    "CalcTimeAT = [flight['arrivalTime'] for flight in CalcTime]\n",
    "\n",
    "CalcArrTime = pd.DataFrame({\n",
    "    'flightID': CalcTimeFI,\n",
    "    'departureTime': CalcTimeDT,\n",
    "    'arrivalTime': CalcTimeAT\n",
    "})\n",
    "\n",
    "df = pd.merge(df, CalcArrTime, on='flightID', how='inner', suffixes=('_orig', '_new'))\n",
    "df['departureTime_orig'] = df['departureTime_new']\n",
    "df = df.drop(columns=['departureTime_new'])\n",
    "df = df.rename(columns={\"departureTime_orig\": \"departureTime\"})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9159/3363927618.py:17: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  lat1, long1, lat2, long2 = map(radians, [lat1, long1, lat2, long2])\n",
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('UES9151GS5', 131878.64866472682), ('EZC9678QI6', 89319.56545915133), ('ONL0812DH1', 54226.202775330195), ('CYJ0225CH1', 54192.180615955105), ('POP2875LH3', 81031.60141156154), ('WTC9125IE5', 59610.494114024346), ('EDV2089LK5', 70430.77109851535), ('HCA3158QA6', 96993.6001387972), ('YMH6360YP0', 76257.83820830849), ('PUD8209OG3', 115812.65317264089), ('PAJ3974RK1', 34229.24258043987), ('WYU2010YH8', 96735.86138266105), ('JJM4724RF7', 93042.65937915725), ('MXU9187YC7', 61040.245306991266), ('HGO4350KK1', 81796.00100445334), ('BWI0520BG6', 124737.25321015735), ('JBE2302VO4', 69002.44956840751), ('DAZ3029XA0', 123082.9234616451), ('PIT2755XC1', 36076.50417601843), ('CKZ3132BR4', 92728.59115309549), ('CXN7304ER2', 78744.14181677988), ('WBE6935NU3', 99159.25968962222), ('IEG9308EA5', 42015.638459926915), ('SJD8775RZ4', 67450.84984178391), ('CDC0302NN5', 63112.87925370441), ('KKP5277HZ7', 58555.91654607691), ('SPR4484HA6', 122258.09879931435), ('VZY2993ME1', 73690.19671385182), ('LLZ3798PE3', 84096.07184097475), ('XFG5747ZT9', 66420.44659568898), ('UMH6360YP0', 3341.2396399015347)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "AirportData = load_dataset(\"Top30_airports_LatLong.csv\", [\"airportName\", \"IATA\", \"Latitude\", \"Longitude\"])\n",
    "\n",
    "def search_airport(data, IATACode):\n",
    "    SpecificAirport = data[data[\"IATA\"] == IATACode]\n",
    "    LatLong = [SpecificAirport[\"Latitude\"], SpecificAirport[\"Longitude\"]]\n",
    "    return LatLong\n",
    "\n",
    "def HaversineEquation(Coordinate1, Coordinate2):\n",
    "\n",
    "    R = 3440.065 #radius of the earth in nautical miles\n",
    "\n",
    "    lat1, long1 = Coordinate1\n",
    "    lat2, long2 = Coordinate2\n",
    "\n",
    "    lat1, long1, lat2, long2 = map(radians, [lat1, long1, lat2, long2])\n",
    "\n",
    "    dlat = lat2-lat1\n",
    "    dlon = long2-long1\n",
    "\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "\n",
    "    return R*c\n",
    "\n",
    "def calculate_distance(pair, data):\n",
    "    origin, destination = pair\n",
    "    originCoordinates = search_airport(data, origin)\n",
    "    destinationCoordinates = search_airport(data, destination)\n",
    "    return HaversineEquation(originCoordinates, destinationCoordinates)\n",
    "\n",
    "def get_nautical_miles(flightID, data):\n",
    "    flight = data[data[\"flightID\"] == flightID]\n",
    "    if not flight.empty:\n",
    "        return flight.iloc[0][\"NauticalMilesDistance\"]\n",
    "    return None\n",
    "\n",
    "\n",
    "try:\n",
    "    df[\"NauticalMilesDistance\"]\n",
    "except:\n",
    "    flightPairs = df[[\"originAirport\", \"destinationAirport\"]].apply(tuple, axis=1)\n",
    "    df[\"NauticalMilesDistance\"] = flightPairs.map(lambda pair: calculate_distance(pair, AirportData))\n",
    "\n",
    "try:\n",
    "    rdd[\"NauticalMilesDistance\"]\n",
    "except:\n",
    "    rdd[\"NauticalMilesDistance\"] = rdd[\"flightID\"].map(lambda flightID: get_nautical_miles(flightID, df))\n",
    "\n",
    "\n",
    "PySdf = spark.createDataFrame(rdd)\n",
    "rdd_data = PySdf.rdd\n",
    "\n",
    "PassengerData = rdd_data.map(lambda row: (row['passengerID'], row['NauticalMilesDistance']))\n",
    "\n",
    "PassengerMilesRDD = PassengerData.reduceByKey(lambda a, b: a+b)\n",
    "PassengerMiles = PassengerMilesRDD.collect()\n",
    "\n",
    "print(PassengerMiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
